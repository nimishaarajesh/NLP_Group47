{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c67bd9f",
   "metadata": {},
   "source": [
    "# Task-3 : Testing Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598fb413",
   "metadata": {},
   "source": [
    "**AIM:**<br>\n",
    "The goal of this task is to create a simple monitoring system that records user inputs and model predictions, along with the date and time of each interaction, in a log file. This system will help us track and review how the model behaves over time, making it easier to debug and analyze its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e27954",
   "metadata": {},
   "source": [
    "**Code Walkthrough:**<br>\n",
    "<br>\n",
    "1.Imports and Endpoint Definition:<br>\n",
    "    -Requests and json libraries are imported to facilitate making HTTP requests and handling JSON data.<br>\n",
    "    -The endpoint URL for the FastAPI service is defined as http://127.0.0.1:5000/predict.<br>\n",
    "<br>\n",
    "2.Test Input Preparation:<br>\n",
    "    -A list of tokens (test_tokens) is defined, representing the input text to be sent to the model.<br>\n",
    "    -The tokens are joined into a single string (test_text) to form the input text in a format suitable for the model.<br>\n",
    "<br>\n",
    "3.Payload Creation:<br>\n",
    "    -A JSON payload is created containing the input text.<br>\n",
    "    -This payload will be sent to the FastAPI endpoint.<br>\n",
    "<br>\n",
    "4.Sending the POST Request:<br>\n",
    "    -The requests.post method is used to send a POST request to the FastAPI endpoint with the JSON payload.<br>\n",
    "    -The Content-Type header is set to application/json to indicate the payload format.<br>\n",
    "<br>\n",
    "5.Handling the Response:<br>\n",
    "    -If the response status code is 200 (indicating success), the response JSON is parsed and printed.<br>\n",
    "    -The model's predictions are mapped to the corresponding tokens in the input text.<br>\n",
    "<br>\n",
    "6.Mapping Model Output to Tokens:<br>\n",
    "    -An empty list model_ner_tags is initialized to store the predicted named entity recognition (NER) tags for each token.<br>\n",
    "    -For each token in test_tokens, the code checks if the token is present in the response JSON.<br>\n",
    "    -If a match is found, the corresponding NER tag is appended to model_ner_tags.<br>\n",
    "    -If no match is found for a token, the default tag 'O' (indicating no entity) is appended.<br>\n",
    "<br>\n",
    "**Output:**<br>\n",
    "The server's response is printed in a formatted JSON structure.\n",
    "The model's NER tags for the input tokens are printed, providing a clear view of the model's predictions for the given input.\n",
    "<br><br>\n",
    "**NOTE**\n",
    "We were supposed to get output as [B-AC, B-O, B-LF, I-LF, I-LF, B-O] for the input ['EPI', '=', 'Echo', 'planar', 'imaging', '.'] . As we are using the model suggested , the output we are getting is using different keywords - ['O', 'LABEL_0', 'LABEL_3', 'O', 'LABEL_4', 'LABEL_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1adcef48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from the server:\n",
      "[\n",
      "  {\n",
      "    \"end\": 1,\n",
      "    \"entity\": \"LABEL_1\",\n",
      "    \"index\": 1,\n",
      "    \"score\": 0.9999969005584717,\n",
      "    \"start\": 0,\n",
      "    \"word\": \"\\u0120E\"\n",
      "  },\n",
      "  {\n",
      "    \"end\": 3,\n",
      "    \"entity\": \"LABEL_1\",\n",
      "    \"index\": 2,\n",
      "    \"score\": 0.9999969005584717,\n",
      "    \"start\": 1,\n",
      "    \"word\": \"PI\"\n",
      "  },\n",
      "  {\n",
      "    \"end\": 5,\n",
      "    \"entity\": \"LABEL_0\",\n",
      "    \"index\": 3,\n",
      "    \"score\": 0.9999929666519165,\n",
      "    \"start\": 4,\n",
      "    \"word\": \"\\u0120=\"\n",
      "  },\n",
      "  {\n",
      "    \"end\": 10,\n",
      "    \"entity\": \"LABEL_3\",\n",
      "    \"index\": 4,\n",
      "    \"score\": 0.9999593496322632,\n",
      "    \"start\": 6,\n",
      "    \"word\": \"\\u0120Echo\"\n",
      "  },\n",
      "  {\n",
      "    \"end\": 15,\n",
      "    \"entity\": \"LABEL_4\",\n",
      "    \"index\": 5,\n",
      "    \"score\": 0.9999880790710449,\n",
      "    \"start\": 11,\n",
      "    \"word\": \"\\u0120plan\"\n",
      "  },\n",
      "  {\n",
      "    \"end\": 17,\n",
      "    \"entity\": \"LABEL_4\",\n",
      "    \"index\": 6,\n",
      "    \"score\": 0.9999884366989136,\n",
      "    \"start\": 15,\n",
      "    \"word\": \"ar\"\n",
      "  },\n",
      "  {\n",
      "    \"end\": 25,\n",
      "    \"entity\": \"LABEL_4\",\n",
      "    \"index\": 7,\n",
      "    \"score\": 0.9999750852584839,\n",
      "    \"start\": 18,\n",
      "    \"word\": \"\\u0120imaging\"\n",
      "  },\n",
      "  {\n",
      "    \"end\": 27,\n",
      "    \"entity\": \"LABEL_0\",\n",
      "    \"index\": 8,\n",
      "    \"score\": 0.9999949932098389,\n",
      "    \"start\": 26,\n",
      "    \"word\": \"\\u0120.\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Model NER Tags:\n",
      "['O', 'LABEL_0', 'LABEL_3', 'O', 'LABEL_4', 'LABEL_0']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the endpoint URL\n",
    "url = \"http://127.0.0.1:5000/predict\"\n",
    "\n",
    "# Define the token input for testing\n",
    "test_tokens = ['EPI', '=', 'Echo', 'planar', 'imaging', '.']\n",
    "test_text = \" \".join(test_tokens)\n",
    "\n",
    "# Create the JSON payload\n",
    "payload = {\n",
    "    \"text\": test_text\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(url, headers={\"Content-Type\": \"application/json\"}, data=json.dumps(payload))\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    \n",
    "        response_json = response.json()\n",
    "        print(\"Response from the server:\")\n",
    "        print(json.dumps(response_json, indent=2))\n",
    "        \n",
    "        # Map the model output to tokens\n",
    "        model_ner_tags = []\n",
    "        for token in test_tokens:\n",
    "            found = False\n",
    "            for item in response_json:\n",
    "                if token in item['word'].strip():\n",
    "                    model_ner_tags.append(item['entity'])\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                model_ner_tags.append('O')  # Default to 'O' if no match is found\n",
    "        \n",
    "        print(\"\\nModel NER Tags:\")\n",
    "        print(model_ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0335f18f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
